{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from random import uniform\n",
    "\n",
    "#-------------------------PREPARATION-----------------------------#\n",
    "\n",
    "def prepare_url(payment, location):\n",
    "    \n",
    "    base_url = f'https://www.mubawab.ma/en/ct/{location}/real-estate-for-{payment}'\n",
    "\n",
    "    return base_url\n",
    "\n",
    "def get_links(url, max_pages=20):\n",
    "    prop_links = []\n",
    "    \n",
    "    page = 1  # Start from the first page\n",
    "    while page <= max_pages:\n",
    "        print(f'Scraping links from page {page}...')\n",
    "        page_url = url + f':p:{page}'\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(page_url)\n",
    "            response.raise_for_status()  # Raise an error for bad status codes\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            listings = soup.find_all('h2', class_='listingTit')\n",
    "\n",
    "            # If no listings are found, break the loop\n",
    "            if not listings:\n",
    "                print(f\"No listings found on page {page}. Stopping pagination.\")\n",
    "                break\n",
    "\n",
    "            for listing in listings:\n",
    "                try:\n",
    "                    link_tag = listing.find('a')\n",
    "                    if link_tag and 'href' in link_tag.attrs:\n",
    "                        link = link_tag['href']\n",
    "                        prop_links.append(link)\n",
    "                    else:\n",
    "                        print(f\"Link not found in listing: {listing}\")\n",
    "                \n",
    "                except AttributeError as e:\n",
    "                    print(f\"Error finding a link: {e}\")\n",
    "\n",
    "            # Check if there is a \"Next\" page\n",
    "            next_page = soup.find('a', class_='arrowDot')\n",
    "            if not next_page:\n",
    "                print(\"No 'Next' page found. Stopping pagination.\")\n",
    "                break\n",
    "        \n",
    "        except requests.exceptions.HTTPError as http_err:\n",
    "            print(f\"HTTP error occurred on page {page}: {http_err}\")\n",
    "            break  # Stop the loop if we hit an HTTP error (like 404)\n",
    "        \n",
    "        except requests.RequestException as req_e:\n",
    "            print(f\"Request error on page {page}: {req_e}\")\n",
    "            break  # Stop the loop for other request issues\n",
    "\n",
    "        print('Sleeping for a bit...')\n",
    "        sleep(uniform(1, 3))  # Random sleep between 1 and 3 seconds\n",
    "\n",
    "        # Increment page counter if there is a next page\n",
    "        page += 1\n",
    "\n",
    "    return prop_links\n",
    "\n",
    "#-------------------------FEATURES--------------------------------#\n",
    "\n",
    "def get_details(links):\n",
    "    full_list = []\n",
    "    for counter, link in enumerate(tqdm(links, desc=\"Fetching property details\")):\n",
    "        try:\n",
    "            counter += 1\n",
    "            response = requests.get(link)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            price = soup.find('h3', class_='orangeTit').text.strip()\n",
    "            \n",
    "            area_text = soup.find('h3', class_='greyTit').text.strip()\n",
    "            pattern = r'^(.*)\\sin\\s(.*)$'\n",
    "\n",
    "            # Use re.search to match both the area and the city\n",
    "            match = re.search(pattern, area_text)\n",
    "\n",
    "            if match:\n",
    "                area = match.group(1).strip()  # First group: Area\n",
    "                city = match.group(2).strip()  # Second group: City\n",
    "            \n",
    "            title = soup.find('h1', class_='searchTitle').text.strip()\n",
    "            \n",
    "            description = soup.find_all('p', class_='adMainFeatureContentValue')\n",
    "\n",
    "            description_titles = ['Property Type', 'Condition', 'Age', 'Floor', 'Orientation', 'Floor']\n",
    "            descriptor_list = [desc.text.strip() for desc in description]\n",
    "\n",
    "            desc_dict = dict(zip(description_titles, descriptor_list))\n",
    "            \n",
    "            size, rooms, bedrooms, bathrooms = None, None, None, None\n",
    "\n",
    "            details = soup.find_all('div', class_='adDetailFeature')\n",
    "\n",
    "            for detail in details:\n",
    "                # Check for size (since it's the first one with 'm²')\n",
    "                if 'm²' in detail.text:\n",
    "                    size = detail.find('span').text.strip().replace('m²', '').strip()\n",
    "                \n",
    "                # Check for number of pieces\n",
    "                if 'Pieces' in detail.text:\n",
    "                    rooms = detail.find('span').text.strip().replace('Pieces', '').strip()\n",
    "                \n",
    "                # Check for number of rooms\n",
    "                if 'Rooms' in detail.text:\n",
    "                    bedrooms = detail.find('span').text.strip().replace('Rooms', '').strip()\n",
    "                \n",
    "                # Check for number of bathrooms\n",
    "                if 'Bathrooms' in detail.text:\n",
    "                    bathrooms = detail.find('span').text.strip().replace('Bathrooms', '').strip()\n",
    "                    \n",
    "            features = soup.find_all('span', class_='fSize11 centered')\n",
    "            feature_list = [feature.text.strip() for feature in features]   \n",
    "            feature_str = ', '.join(feature_list)\n",
    "                     \n",
    "            property_details = {\n",
    "                                'Title': title,\n",
    "                                'City' : city, \n",
    "                                'Area': area, \n",
    "                                'Size': size, \n",
    "                                'Rooms': rooms, \n",
    "                                'Bedrooms': bedrooms, \n",
    "                                'Bathrooms': bathrooms, \n",
    "                                'Price': price,\n",
    "                                'Features': feature_str\n",
    "                                }\n",
    "            \n",
    "            all_details = {**property_details, **desc_dict}\n",
    "            \n",
    "            full_list.append(all_details)\n",
    "            \n",
    "            sleep(uniform(1, 3))\n",
    "            \n",
    "        except requests.RequestException as req_e:\n",
    "            print(f'Error fetching property data: {req_e}')\n",
    "        except AttributeError as attr_e:\n",
    "            print(f'Missing element in the page: {attr_e}')\n",
    "            \n",
    "    return pd.DataFrame(full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Casablanca\n",
      "Scraping links from page 1...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Al Boustane</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 2...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Rio Beach </h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 3...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Anfa Blue Living Villas</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 4...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Dyour Tamaris</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 5...\n",
      "Link not found in listing: <h2 class=\"listingTit\">DIAZ Residence</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 6...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Douirti Invest</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 7...\n",
      "Link not found in listing: <h2 class=\"listingTit\">DIAZ Residence</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 8...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Missimi Office</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 9...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Douirti Invest</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 10...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Lotissement Miftah El Kheir Settat R+2 to  R+5 </h2>\n",
      "Sleeping for a bit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching property details: 100%|██████████| 330/330 [15:01<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Marrakech\n",
      "Scraping links from page 1...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Menzah Annakhil Tranche 1</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 2...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Lotissement Jnane El Kheir 1, 2 et 3 à Benguerir</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 3...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Signature Luxury Villa 2</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 4...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Abouab Al Falah</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 5...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Menzah Annakhil Tranche 2</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 6...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Signature Luxury Villa 2</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 7...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Oasis Atlas Resort - Villas</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 8...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Lotissement Jnane El Kheir 1, 2 et 3 à Benguerir</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 9...\n",
      "Link not found in listing: <h2 class=\"listingTit\">SHEMS AL MADINA - LAND LOTS R 1</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 10...\n",
      "Link not found in listing: <h2 class=\"listingTit\">The Residences Riad Marrakech</h2>\n",
      "Sleeping for a bit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching property details: 100%|██████████| 330/330 [14:56<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Rabat\n",
      "Scraping links from page 1...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Résidence fermée de villas isolées : 18M Avenue</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 2...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Residence Yassmine Temara</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 3...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Residence Yassmine Temara</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 4...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aday litaamir</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 5...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Résidence fermée de villas isolées : 18M Avenue</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 6...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Residence Yassmine Temara</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 7...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Residence Yassmine Temara</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 8...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Al Baraka</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 9...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Al Baraka</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 10...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Residence Yassmine Temara</h2>\n",
      "Sleeping for a bit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching property details: 100%|██████████| 330/330 [14:56<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Tanger\n",
      "Scraping links from page 1...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aquarelle Residence Marina Bay -B</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 2...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aquarelle Residences Marina Bay</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 3...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Les Jardins de Mesnana Golf</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 4...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aquarelle Residence Marina Bay -B</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 5...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aquarelle Residences Marina Bay</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 6...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Les Jardins de Mesnana Golf</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 7...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aquarelle Residences Marina Bay</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 8...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Les Jardins de Mesnana Golf</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 9...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aquarelle Residence Marina Bay -B</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 10...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aquarelle Residences Marina Bay</h2>\n",
      "Sleeping for a bit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching property details: 100%|██████████| 330/330 [15:18<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Agadir\n",
      "Scraping links from page 1...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 2...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 3...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 4...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 5...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 6...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 7...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 8...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 9...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 10...\n",
      "Sleeping for a bit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching property details: 100%|██████████| 330/330 [15:28<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Fès\n",
      "Scraping links from page 1...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 2...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 3...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 4...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 5...\n",
      "No 'Next' page found. Stopping pagination.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching property details: 100%|██████████| 163/163 [07:22<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Kénitra\n",
      "Scraping links from page 1...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Residence Yassmine Temara</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 2...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Residence Yassmine Temara</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 3...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Al Baraka</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 4...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Residence Yassmine Temara</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 5...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aday litaamir</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 6...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Al Baraka</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 7...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aday litaamir</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 8...\n",
      "No 'Next' page found. Stopping pagination.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching property details: 100%|██████████| 262/262 [11:58<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Mohammédia\n",
      "Scraping links from page 1...\n",
      "Link not found in listing: <h2 class=\"listingTit\">LARIMAR residence</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 2...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Marina Sidi Rehal</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 3...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Gardenia Zenata Park</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 4...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Anaé Garden &amp; Sea</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 5...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Les Beaux Rivages</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 6...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Natura</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 7...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Gardenia Zenata Park</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 8...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Chraibi Real Estate</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 9...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Al Boustane</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 10...\n",
      "No 'Next' page found. Stopping pagination.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching property details: 100%|██████████| 322/322 [14:08<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Salé\n",
      "Scraping links from page 1...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aday litaamir</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 2...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aday litaamir</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 3...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Résidence fermée de villas isolées : 18M Avenue</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 4...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Résidence fermée de villas isolées : 18M Avenue</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 5...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Résidence fermée de villas isolées : 18M Avenue</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 6...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Al Baraka</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 7...\n",
      "No 'Next' page found. Stopping pagination.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching property details: 100%|██████████| 210/210 [09:34<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Bouskoura\n",
      "Scraping links from page 1...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Ahl Loghlam - Moyen standing-Tit Mellil</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 2...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Gardenia Zenata Park</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 3...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Missimi Living</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 4...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Missimi Living</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 5...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Les Jardins de Ain Sebâa</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 6...\n",
      "Link not found in listing: <h2 class=\"listingTit\">DIAZ Residence</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 7...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Kanzi Subdivision</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 8...\n",
      "Link not found in listing: <h2 class=\"listingTit\">THE AGATES</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 9...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Les Beaux Rivages</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 10...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Ain Sebaâ Square </h2>\n",
      "Sleeping for a bit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching property details: 100%|██████████| 330/330 [14:56<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Temara\n",
      "Scraping links from page 1...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aday litaamir</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 2...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Al Baraka</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 3...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Résidence fermée de villas isolées : 18M Avenue</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 4...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aday litaamir</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 5...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Résidence fermée de villas isolées : 18M Avenue</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 6...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Al Baraka</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 7...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Aday litaamir</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 8...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Residence Yassmine Temara</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 9...\n",
      "No 'Next' page found. Stopping pagination.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching property details: 100%|██████████| 283/283 [12:36<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Essaouira\n",
      "Scraping links from page 1...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Residence ALMARWA</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 2...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Abouab Al Falah</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 3...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Abouab Al Falah</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 4...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Abouab Al Falah</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 5...\n",
      "Link not found in listing: <h2 class=\"listingTit\">Residence ALMARWA</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 6...\n",
      "Link not found in listing: <h2 class=\"listingTit\">SHEMS AL MADINA - LAND LOTS R 1</h2>\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 7...\n",
      "No 'Next' page found. Stopping pagination.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching property details: 100%|██████████| 209/209 [09:31<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Meknes\n",
      "Scraping links from page 1...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 2...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 3...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 4...\n",
      "Sleeping for a bit...\n",
      "Scraping links from page 5...\n",
      "No 'Next' page found. Stopping pagination.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching property details: 100%|██████████| 165/165 [07:25<00:00,  2.70s/it]\n"
     ]
    }
   ],
   "source": [
    "cities = ['casablanca', 'marrakech', 'rabat', 'tanger', 'agadir', 'fès', 'kénitra', 'mohammédia', 'salé', 'bouskoura', 'temara', 'essaouira', 'meknes']\n",
    "\n",
    "def scrape_property_data(payment, city):\n",
    "    base_url = prepare_url(payment, city)\n",
    "    prop_links = get_links(base_url, max_pages=10)\n",
    "    df = get_details(prop_links)\n",
    "    \n",
    "    return df\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for city in cities:\n",
    "    print(f'Scraping data for {city.title()}')\n",
    "    city_df = scrape_property_data('rent', city)\n",
    "    all_dfs.append(city_df)\n",
    "    \n",
    "all_property_data = pd.concat(all_dfs, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_property_data.to_pickle('property_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_property_data.to_csv('property_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[164], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mall_property_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPrice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[^0-9]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data-science/lib/python3.10/site-packages/pandas/core/generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/data-science/lib/python3.10/site-packages/pandas/core/internals/managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data-science/lib/python3.10/site-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/miniconda3/envs/data-science/lib/python3.10/site-packages/pandas/core/internals/blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/data-science/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/data-science/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/data-science/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "all_property_data.Price.str.replace(\"[^0-9]\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
